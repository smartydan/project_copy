{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05c7131f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "from gpt_classes.GPTModel import GPTModel\n",
    "from gpt_classes.GPTDataset import GPTDataset\n",
    "from classes.Preprocessor import Preprocessor\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from dicts import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f0c6271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document.id</th>\n",
       "      <th>source</th>\n",
       "      <th>stage</th>\n",
       "      <th>source_text</th>\n",
       "      <th>lemm_text</th>\n",
       "      <th>city</th>\n",
       "      <th>region</th>\n",
       "      <th>date</th>\n",
       "      <th>data</th>\n",
       "      <th>assessor</th>\n",
       "      <th>...</th>\n",
       "      <th>represent_ethicity_meaning</th>\n",
       "      <th>is_ethicity_superior_raw</th>\n",
       "      <th>is_ethicity_superior_meaning</th>\n",
       "      <th>is_ethicity_aggressor_raw</th>\n",
       "      <th>is_ethicity_aggressor_meaning</th>\n",
       "      <th>is_ethicity_dangerous_raw</th>\n",
       "      <th>is_ethicity_dangerous_meaning</th>\n",
       "      <th>comment</th>\n",
       "      <th>old_id</th>\n",
       "      <th>text_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65990</th>\n",
       "      <td>938463132</td>\n",
       "      <td>iqbuzz</td>\n",
       "      <td>3</td>\n",
       "      <td>Едут в купе армянин, грузин и русский. Вдруг г...</td>\n",
       "      <td>ехать купе армянин грузин русский грузин пукну...</td>\n",
       "      <td>Нарьян-Мар</td>\n",
       "      <td>Ненецкий АО</td>\n",
       "      <td>2015-06-22</td>\n",
       "      <td>2017-03-15 13:48:01</td>\n",
       "      <td>mintbreeze</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>938463132</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4513</th>\n",
       "      <td>442314563</td>\n",
       "      <td>iqbuzz</td>\n",
       "      <td>2</td>\n",
       "      <td>Уважаемые Украинцы - настоящие Украинцы, не пр...</td>\n",
       "      <td>уважаемый украинец настоящий украинец предават...</td>\n",
       "      <td>Москва</td>\n",
       "      <td>Москва</td>\n",
       "      <td>2014-04-13</td>\n",
       "      <td>2016-09-30 23:35:57</td>\n",
       "      <td>an_men</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>3.0</td>\n",
       "      <td>irrel</td>\n",
       "      <td>3.0</td>\n",
       "      <td>irrel</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>басурман_62</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       document.id  source  stage  \\\n",
       "65990    938463132  iqbuzz      3   \n",
       "4513     442314563  iqbuzz      2   \n",
       "\n",
       "                                             source_text  \\\n",
       "65990  Едут в купе армянин, грузин и русский. Вдруг г...   \n",
       "4513   Уважаемые Украинцы - настоящие Украинцы, не пр...   \n",
       "\n",
       "                                               lemm_text        city  \\\n",
       "65990  ехать купе армянин грузин русский грузин пукну...  Нарьян-Мар   \n",
       "4513   уважаемый украинец настоящий украинец предават...      Москва   \n",
       "\n",
       "            region        date                 data    assessor  ...  \\\n",
       "65990  Ненецкий АО  2015-06-22  2017-03-15 13:48:01  mintbreeze  ...   \n",
       "4513        Москва  2014-04-13  2016-09-30 23:35:57      an_men  ...   \n",
       "\n",
       "      represent_ethicity_meaning  is_ethicity_superior_raw  \\\n",
       "65990                        NaN                       NaN   \n",
       "4513                          no                       3.0   \n",
       "\n",
       "      is_ethicity_superior_meaning  is_ethicity_aggressor_raw  \\\n",
       "65990                          NaN                        NaN   \n",
       "4513                         irrel                        3.0   \n",
       "\n",
       "      is_ethicity_aggressor_meaning is_ethicity_dangerous_raw  \\\n",
       "65990                           NaN                       NaN   \n",
       "4513                          irrel                       1.0   \n",
       "\n",
       "       is_ethicity_dangerous_meaning  comment       old_id text_sentiment  \n",
       "65990                            NaN      NaN    938463132            NaN  \n",
       "4513                              no      NaN  басурман_62            NaN  \n",
       "\n",
       "[2 rows x 62 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir = 'data/'\n",
    "df = pd.read_csv(os.path.join(base_dir, 'df.csv'), low_memory=False)\n",
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea09ec98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python311\\Lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "models_directory = 'models'\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = GPTModel(device).to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01ec93a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(models_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7511a1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = df['document.id'].unique()\n",
    "ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3842a16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59, 62), (20, 62), (21, 62))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_STATE = 42\n",
    "process_ids, test_ids = train_test_split(ids, test_size=0.2, random_state=RANDOM_STATE)\n",
    "train_ids, validate_ids = train_test_split(process_ids, train_size=0.75, random_state=RANDOM_STATE)\n",
    "\n",
    "train = df.loc[df['document.id'].isin(train_ids)]\n",
    "test = df.loc[df['document.id'].isin(test_ids)]\n",
    "validate = df.loc[df['document.id'].isin(validate_ids)]\n",
    "train.shape, test.shape, validate.shape  # percents are ≈ (60%, 20%, 20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63079704",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessor(df=df, args=args, var_vocab=var_vocab, topic_to_russian=topic_to_russian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e072c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(model):\n",
    "    torch.cuda.empty_cache()\n",
    "    all_generated = []\n",
    "    all_targets = []\n",
    "    \n",
    "    test_dataset = GPTDataset(test.copy(), args=args, preprocessor=preprocessor, sp=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (data, cut_data, ids_) in enumerate(tqdm(test_loader), 1):\n",
    "            outputs = model(data, cut_data)\n",
    "\n",
    "\n",
    "            for descr, id_ in zip(data, ids_):\n",
    "                # descr = el.split(\"Описание: \", 1)[1]\n",
    "                # all_targets.append(descr)\n",
    "                all_targets.append(id_.item())\n",
    "                \n",
    "            generated = model.my_generate(cut_data)\n",
    "            all_generated.extend(generated)\n",
    "    \n",
    "    return all_targets, all_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3582eaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_num = 2\n",
    "\n",
    "def define(x):\n",
    "    counts = x.value_counts(dropna=False)\n",
    "    mode = counts.iloc[0]\n",
    "    if mode >= people_num and np.sum(counts == mode) == 1:\n",
    "        return counts.index[0]\n",
    "    return None\n",
    "\n",
    "def get_info(data, var, ethnicity=None):\n",
    "    if ethnicity:\n",
    "        data_cur = data[data['seed_eth_group'] == ethnicity][var]\n",
    "    else:\n",
    "        data_cur = data.drop_duplicates(subset='assessor')[var]\n",
    "    \n",
    "    value = define(data_cur)\n",
    "    labels = var_vocab[var]['labels']\n",
    "    if value and value in labels:\n",
    "        return labels[value]\n",
    "\n",
    "def fit(id_, text):\n",
    "    \n",
    "    cnt = 0\n",
    "\n",
    "    data = df.loc[df['document.id'] == id_]\n",
    "    sz = data.shape[0]\n",
    "\n",
    "    if sz == 0:\n",
    "        return None\n",
    "\n",
    "    eths = data['seed_eth_group'].unique()\n",
    "\n",
    "    for var in args:\n",
    "        if var_vocab[var]['aspect_level']:\n",
    "            for eth in eths:\n",
    "                info = get_info(data, var, eth)\n",
    "                if info:\n",
    "                    cnt += (info in text and 'не ' + info not in text)\n",
    "        else:\n",
    "            info = get_info(data, var)\n",
    "            if info:\n",
    "                cnt += (info in text and 'не ' + info not in text)\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "661929fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(ids_, generated):\n",
    "    cnt = 0\n",
    "    for (id_, text) in zip(ids_, generated):\n",
    "        cnt += fit(id_, text)\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc08f526",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2e5ff84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading epoch_0_num_3_loss_0.6914989824026403 model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a0c65553544d2f85fdbec73d4f0dd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading epoch_3_num_16_loss_2.3076344839284118 model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea5a614859d34d1a842d87cf9df4fb3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for filename in files:\n",
    "    print(f'loading {filename} model')\n",
    "    path = os.path.join(models_directory, filename)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    targets, generated = gen(model)\n",
    "    cnt = get_score(targets, generated)\n",
    "    results[filename] = cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fbe9c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_0_num_3_loss_0.6914989824026403 model score is 0\n",
      "epoch_3_num_16_loss_2.3076344839284118 model score is 0\n"
     ]
    }
   ],
   "source": [
    "for name, cnt in results.items():\n",
    "    print(f'{name} model score is {cnt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b29a26a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gpt_scores.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f853b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
